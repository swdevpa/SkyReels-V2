{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# üé¨ SkyReels V2 - Infinite-Length Film Generator\n",
        "\n",
        "Welcome to SkyReels V2! This notebook provides an easy-to-use interface for generating high-quality videos using the SkyReels V2 models.\n",
        "\n",
        "**Features:**\n",
        "- Text-to-Video Generation\n",
        "- Image-to-Video Generation  \n",
        "- Diffusion Forcing for Long Videos\n",
        "- Multiple Resolution Support (540P/720P)\n",
        "- Interactive Web Interface\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## üöÄ Setup and Installation\n",
        "\n",
        "First, let's install all required dependencies and clone the repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install system dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq ffmpeg libsm6 libxext6 libxrender-dev libglib2.0-0\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/SkyworkAI/SkyReels-V2.git\n",
        "%cd SkyReels-V2\n",
        "\n",
        "# Install Python dependencies\n",
        "!pip install -q torch==2.5.1 torchvision==0.20.1\n",
        "!pip install -q diffusers>=0.31.0 transformers==4.49.0 tokenizers==0.21.1\n",
        "!pip install -q accelerate==1.6.0 tqdm imageio easydict ftfy\n",
        "!pip install -q opencv-python==4.10.0.84 imageio-ffmpeg\n",
        "!pip install -q numpy>=1.23.5,<2\n",
        "!pip install -q gradio spaces\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "# Install video processing dependencies\n",
        "!pip install -q decord\n",
        "!pip install -q av\n",
        "\n",
        "# Install xfuser for multi-GPU support (optional)\n",
        "!pip install -q xfuser\n",
        "\n",
        "print(\"‚úÖ Installation completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîß Quick Fix for Missing Dependencies\n",
        "\n",
        "If you encounter \"ModuleNotFoundError\" for decord or other modules, run this cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick fix for missing dependencies\n",
        "print(\"üîß Installing missing video processing dependencies...\")\n",
        "\n",
        "# Install decord and other video dependencies\n",
        "!pip install -q decord av\n",
        "!pip install -q dashscope  # Also needed for some pipelines\n",
        "\n",
        "# Verify installations\n",
        "try:\n",
        "    import decord\n",
        "    print(\"‚úÖ decord installed successfully\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå decord installation failed\")\n",
        "\n",
        "try:\n",
        "    import av\n",
        "    print(\"‚úÖ av installed successfully\") \n",
        "except ImportError:\n",
        "    print(\"‚ùå av installation failed\")\n",
        "\n",
        "print(\"üîÑ Please restart runtime if issues persist: Runtime ‚Üí Restart runtime\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üíΩ Disk Space Management\n",
        "\n",
        "Google Colab has limited disk space (~112GB). Large AI models can quickly fill this up. Use these tools to manage space:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def check_disk_usage():\n",
        "    \"\"\"Check current disk usage and identify large files/folders\"\"\"\n",
        "    print(\"=== Disk Usage Check ===\")\n",
        "    \n",
        "    # Get overall disk usage\n",
        "    total, used, free = shutil.disk_usage('/')\n",
        "    print(f\"üíΩ Total: {total//1024**3:.1f}GB\")\n",
        "    print(f\"üìä Used: {used//1024**3:.1f}GB ({used/total*100:.1f}%)\")\n",
        "    print(f\"üÜì Free: {free//1024**3:.1f}GB\")\n",
        "    \n",
        "    if free < 5*1024**3:  # Less than 5GB free\n",
        "        print(\"‚ö†Ô∏è  WARNING: Low disk space!\")\n",
        "    \n",
        "    print(\"\\n=== Largest Folders ===\")\n",
        "    # Find largest folders\n",
        "    try:\n",
        "        result = subprocess.run(['du', '-sh', '/content/*'], \n",
        "                              capture_output=True, text=True, shell=True)\n",
        "        if result.stdout:\n",
        "            lines = result.stdout.strip().split('\\n')\n",
        "            # Sort by size (rough sorting by first character/number)\n",
        "            for line in sorted(lines, reverse=True)[:10]:\n",
        "                if line.strip():\n",
        "                    print(f\"üìÅ {line}\")\n",
        "    except:\n",
        "        print(\"Could not get folder sizes\")\n",
        "\n",
        "def cleanup_colab_space():\n",
        "    \"\"\"Clean up common space-wasting files in Colab\"\"\"\n",
        "    print(\"=== Cleaning Up Disk Space ===\")\n",
        "    \n",
        "    cleanup_commands = [\n",
        "        # Clear pip cache\n",
        "        \"pip cache purge\",\n",
        "        # Clear apt cache  \n",
        "        \"apt-get clean\",\n",
        "        # Remove temp files\n",
        "        \"rm -rf /tmp/*\",\n",
        "        # Clear Python cache\n",
        "        \"find /content -name '__pycache__' -type d -exec rm -rf {} +\",\n",
        "        # Clear .pyc files\n",
        "        \"find /content -name '*.pyc' -delete\",\n",
        "    ]\n",
        "    \n",
        "    for cmd in cleanup_commands:\n",
        "        try:\n",
        "            print(f\"üßπ Running: {cmd}\")\n",
        "            os.system(cmd)\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    print(\"‚úÖ Basic cleanup completed!\")\n",
        "\n",
        "def free_model_cache():\n",
        "    \"\"\"Clear model caches and temporary files\"\"\"\n",
        "    print(\"=== Clearing Model Caches ===\")\n",
        "    \n",
        "    # Clear HuggingFace cache\n",
        "    hf_cache_dir = \"/root/.cache/huggingface\"\n",
        "    if os.path.exists(hf_cache_dir):\n",
        "        try:\n",
        "            shutil.rmtree(hf_cache_dir)\n",
        "            print(f\"üóëÔ∏è  Cleared HuggingFace cache: {hf_cache_dir}\")\n",
        "        except:\n",
        "            print(\"‚ùå Could not clear HuggingFace cache\")\n",
        "    \n",
        "    # Clear torch cache\n",
        "    torch_cache_dir = \"/root/.cache/torch\"\n",
        "    if os.path.exists(torch_cache_dir):\n",
        "        try:\n",
        "            shutil.rmtree(torch_cache_dir)\n",
        "            print(f\"üóëÔ∏è  Cleared PyTorch cache: {torch_cache_dir}\")\n",
        "        except:\n",
        "            print(\"‚ùå Could not clear PyTorch cache\")\n",
        "    \n",
        "    # Clear outputs folder if exists\n",
        "    if os.path.exists(\"outputs\"):\n",
        "        size = sum(os.path.getsize(os.path.join(\"outputs\", f)) \n",
        "                  for f in os.listdir(\"outputs\"))\n",
        "        print(f\"üìÅ outputs folder: {size//1024**2:.1f}MB\")\n",
        "        \n",
        "        # Ask before deleting outputs\n",
        "        response = input(\"Delete generated videos in outputs/? (y/n): \")\n",
        "        if response.lower() == 'y':\n",
        "            shutil.rmtree(\"outputs\")\n",
        "            os.makedirs(\"outputs\", exist_ok=True)\n",
        "            print(\"üóëÔ∏è  Cleared outputs folder\")\n",
        "\n",
        "# Run disk check\n",
        "check_disk_usage()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### üÜò Emergency Disk Cleanup\n",
        "\n",
        "If your disk is full, run these commands immediately:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üÜò EMERGENCY CLEANUP - Run this if disk is full!\n",
        "\n",
        "print(\"üö® Emergency disk cleanup starting...\")\n",
        "\n",
        "# 1. Clear all caches immediately\n",
        "!pip cache purge\n",
        "!apt-get clean\n",
        "\n",
        "# 2. Remove temporary files\n",
        "!rm -rf /tmp/*\n",
        "!rm -rf /var/tmp/*\n",
        "\n",
        "# 3. Clear Python caches\n",
        "!find /content -name '__pycache__' -type d -exec rm -rf {} + 2>/dev/null\n",
        "!find /content -name '*.pyc' -delete 2>/dev/null\n",
        "\n",
        "# 4. Clear HuggingFace cache (models will re-download when needed)\n",
        "!rm -rf /root/.cache/huggingface/\n",
        "\n",
        "# 5. Clear PyTorch cache\n",
        "!rm -rf /root/.cache/torch/\n",
        "\n",
        "# 6. Remove any existing outputs\n",
        "!rm -rf outputs/\n",
        "\n",
        "# 7. Clear notebook checkpoints\n",
        "!find /content -name '.ipynb_checkpoints' -type d -exec rm -rf {} + 2>/dev/null\n",
        "\n",
        "print(\"‚úÖ Emergency cleanup completed!\")\n",
        "\n",
        "# Check space after cleanup\n",
        "total, used, free = shutil.disk_usage('/')\n",
        "print(f\"üÜì Free space after cleanup: {free//1024**3:.1f}GB\")\n",
        "\n",
        "if free < 2*1024**3:  # Still less than 2GB\n",
        "    print(\"‚ö†Ô∏è  Still low on space! Consider:\")\n",
        "    print(\"   - Restarting runtime completely\")\n",
        "    print(\"   - Using smaller models (1.3B instead of 14B)\")\n",
        "    print(\"   - Generating shorter videos\")\n",
        "    print(\"   - Upgrading to Colab Pro for more space\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîß Quick Fix for Module Import Issues\n",
        "\n",
        "If you get \"No module named 'skyreels_v2_infer'\", run this cell to setup the environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ QUICK SETUP - Run this if you get import errors!\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"üîß Quick setup starting...\")\n",
        "\n",
        "# Check current directory\n",
        "current_dir = os.getcwd()\n",
        "print(f\"üìÅ Current directory: {current_dir}\")\n",
        "\n",
        "# Check if we're in SkyReels-V2 directory\n",
        "if not os.path.exists(\"skyreels_v2_infer\"):\n",
        "    print(\"üì• SkyReels-V2 not found, cloning repository...\")\n",
        "    \n",
        "    # Clone the repository\n",
        "    !git clone https://github.com/SkyworkAI/SkyReels-V2.git\n",
        "    \n",
        "    # Change to the directory\n",
        "    os.chdir(\"/content/SkyReels-V2\")\n",
        "    print(f\"üìÇ Changed to: {os.getcwd()}\")\n",
        "else:\n",
        "    print(\"‚úÖ SkyReels-V2 already exists\")\n",
        "\n",
        "# Verify the module exists\n",
        "if os.path.exists(\"skyreels_v2_infer\"):\n",
        "    print(\"‚úÖ skyreels_v2_infer module found!\")\n",
        "    \n",
        "    # List contents to verify\n",
        "    contents = os.listdir(\"skyreels_v2_infer\")\n",
        "    print(f\"üìã Module contents: {contents}\")\n",
        "else:\n",
        "    print(\"‚ùå skyreels_v2_infer module not found!\")\n",
        "    print(\"üîÑ Try running the installation cells first\")\n",
        "\n",
        "# Install missing dependencies if needed\n",
        "print(\"\\nüì¶ Installing missing dependencies...\")\n",
        "!pip install -q decord av dashscope\n",
        "\n",
        "print(\"‚úÖ Quick setup completed!\")\n",
        "print(\"üîÑ Now try importing the modules again\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ‚ö° One-Click Complete Setup\n",
        "\n",
        "**For immediate use: Run this cell to install everything and start the interface!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö° ONE-CLICK SETUP - Run this cell for complete installation!\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def run_command(cmd, description):\n",
        "    \"\"\"Run a command and show progress\"\"\"\n",
        "    print(f\"üîÑ {description}...\")\n",
        "    try:\n",
        "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úÖ {description} completed\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è {description} had warnings: {result.stderr[:100]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå {description} failed: {e}\")\n",
        "\n",
        "print(\"üöÄ Starting complete SkyReels V2 setup...\")\n",
        "\n",
        "# 1. System dependencies\n",
        "run_command(\"apt-get update -qq\", \"Updating system packages\")\n",
        "run_command(\"apt-get install -y -qq ffmpeg libsm6 libxext6 libxrender-dev libglib2.0-0\", \"Installing system dependencies\")\n",
        "\n",
        "# 2. Clone repository if not exists\n",
        "if not os.path.exists(\"/content/SkyReels-V2\"):\n",
        "    run_command(\"cd /content && git clone https://github.com/SkyworkAI/SkyReels-V2.git\", \"Cloning SkyReels-V2 repository\")\n",
        "\n",
        "# 3. Change to directory\n",
        "os.chdir(\"/content/SkyReels-V2\")\n",
        "print(f\"üìÇ Changed to: {os.getcwd()}\")\n",
        "\n",
        "# 4. Install Python dependencies\n",
        "packages = [\n",
        "    \"torch==2.5.1 torchvision==0.20.1\",\n",
        "    \"diffusers>=0.31.0 transformers==4.49.0 tokenizers==0.21.1\", \n",
        "    \"accelerate==1.6.0 tqdm imageio easydict ftfy\",\n",
        "    \"opencv-python==4.10.0.84 imageio-ffmpeg\",\n",
        "    \"gradio spaces huggingface_hub\",\n",
        "    \"numpy>=1.23.5,<2\",\n",
        "    \"decord av dashscope\",  # Video processing\n",
        "    \"xfuser\"  # Multi-GPU support\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    run_command(f\"pip install -q {package}\", f\"Installing {package.split()[0]}\")\n",
        "\n",
        "# 5. Verify installation\n",
        "print(\"\\nüîç Verifying installation...\")\n",
        "\n",
        "# Check GPU\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"‚úÖ GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU detected - please enable GPU runtime\")\n",
        "\n",
        "# Check modules\n",
        "try:\n",
        "    from skyreels_v2_infer.modules import download_model\n",
        "    print(\"‚úÖ SkyReels modules available\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå SkyReels modules not found\")\n",
        "\n",
        "# Check disk space\n",
        "import shutil\n",
        "total, used, free = shutil.disk_usage('/')\n",
        "print(f\"üíΩ Disk space: {free//1024**3:.1f}GB free / {total//1024**3:.1f}GB total\")\n",
        "\n",
        "print(\"\\nüéâ Setup completed! You can now run the interface cells below.\")\n",
        "print(\"üí° Tip: Use 1.3B models if you have limited GPU memory or disk space.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîß Module Import Fix\n",
        "\n",
        "If setup completed but modules weren't found, run this cell to fix the Python path:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß MODULE IMPORT FIX - Run this if modules not found after setup\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"üîß Fixing module imports...\")\n",
        "\n",
        "# 1. Ensure we're in the right directory\n",
        "target_dir = \"/content/SkyReels-V2\"\n",
        "if os.getcwd() != target_dir:\n",
        "    os.chdir(target_dir)\n",
        "    print(f\"üìÇ Changed to: {os.getcwd()}\")\n",
        "\n",
        "# 2. Add to Python path\n",
        "if target_dir not in sys.path:\n",
        "    sys.path.insert(0, target_dir)\n",
        "    print(f\"üìç Added {target_dir} to Python path\")\n",
        "\n",
        "# 3. Verify directory structure\n",
        "if os.path.exists(\"skyreels_v2_infer\"):\n",
        "    print(\"‚úÖ skyreels_v2_infer directory found\")\n",
        "    \n",
        "    # List contents\n",
        "    contents = os.listdir(\"skyreels_v2_infer\")\n",
        "    print(f\"üìã Contents: {contents[:5]}...\")  # Show first 5 items\n",
        "    \n",
        "    # Check specific modules\n",
        "    modules_to_check = [\"modules\", \"pipelines\", \"__init__.py\"]\n",
        "    for module in modules_to_check:\n",
        "        path = os.path.join(\"skyreels_v2_infer\", module)\n",
        "        if os.path.exists(path):\n",
        "            print(f\"‚úÖ {module} found\")\n",
        "        else:\n",
        "            print(f\"‚ùå {module} missing\")\n",
        "else:\n",
        "    print(\"‚ùå skyreels_v2_infer directory not found!\")\n",
        "    print(\"üîÑ Repository may not be fully cloned\")\n",
        "\n",
        "# 4. Test import\n",
        "try:\n",
        "    from skyreels_v2_infer.modules import download_model\n",
        "    print(\"‚úÖ download_model imported successfully!\")\n",
        "    \n",
        "    from skyreels_v2_infer.pipelines import Text2VideoPipeline, Image2VideoPipeline\n",
        "    print(\"‚úÖ Pipeline modules imported successfully!\")\n",
        "    \n",
        "    print(\"üéâ All modules working correctly!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import still failing: {e}\")\n",
        "    print(\"üîÑ Possible solutions:\")\n",
        "    print(\"   1. Restart runtime: Runtime ‚Üí Restart runtime\")\n",
        "    print(\"   2. Re-run the One-Click Setup\")\n",
        "    print(\"   3. Manual clone: !git clone https://github.com/SkyworkAI/SkyReels-V2.git\")\n",
        "\n",
        "# 5. Check disk space again\n",
        "import shutil\n",
        "total, used, free = shutil.disk_usage('/')\n",
        "print(f\"\\nüíΩ Current disk space: {free//1024**3:.1f}GB free\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üÜò Emergency Alternative - Direct Interface\n",
        "\n",
        "If imports still fail, use this simplified version that downloads and runs everything directly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üÜò EMERGENCY DIRECT INTERFACE - Use if normal imports fail\n",
        "\n",
        "# Install dependencies directly\n",
        "!pip install -q gradio huggingface_hub\n",
        "\n",
        "# Download and run the standalone interface\n",
        "!wget -q https://raw.githubusercontent.com/SkyworkAI/SkyReels-V2/main/skyreels_gradio_interface.py -O /content/skyreels_interface.py\n",
        "\n",
        "# Modify the script to add proper imports\n",
        "import os\n",
        "os.chdir(\"/content/SkyReels-V2\")\n",
        "\n",
        "# Direct execution\n",
        "print(\"üöÄ Starting emergency interface...\")\n",
        "print(\"üìÅ Current directory:\", os.getcwd())\n",
        "\n",
        "# Check if modules exist\n",
        "if os.path.exists(\"skyreels_v2_infer\"):\n",
        "    print(\"‚úÖ SkyReels modules found, attempting direct execution...\")\n",
        "    \n",
        "    # Try to run the interface directly\n",
        "    try:\n",
        "        exec(open('/content/skyreels_interface.py').read())\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Direct execution failed: {e}\")\n",
        "        print(\"üîÑ Please try restarting runtime and running One-Click Setup again\")\n",
        "else:\n",
        "    print(\"‚ùå SkyReels-V2 not properly installed\")\n",
        "    print(\"üîÑ Solutions:\")\n",
        "    print(\"   1. Restart runtime completely\")\n",
        "    print(\"   2. Re-run One-Click Setup\")\n",
        "    print(\"   3. Manual installation:\")\n",
        "    print(\"      !rm -rf /content/SkyReels-V2\")\n",
        "    print(\"      !git clone https://github.com/SkyworkAI/SkyReels-V2.git /content/SkyReels-V2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîë Hugging Face Access Token Setup\n",
        "\n",
        "SkyReels V2 models require a Hugging Face account and access token. Set it up here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîë HUGGING FACE TOKEN SETUP\n",
        "\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "import getpass\n",
        "\n",
        "print(\"üîë Hugging Face Access Token Setup\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check if token is already set\n",
        "try:\n",
        "    from huggingface_hub import HfFolder\n",
        "    existing_token = HfFolder.get_token()\n",
        "    if existing_token:\n",
        "        print(\"‚úÖ Token already configured!\")\n",
        "        print(f\"üîê Token: {existing_token[:8]}...{existing_token[-8:]}\")\n",
        "        print(\"üîÑ To change token, continue below\")\n",
        "    else:\n",
        "        print(\"‚ùå No token found\")\n",
        "except:\n",
        "    print(\"‚ùå No token found\")\n",
        "\n",
        "print(\"\\nüìù How to get your Hugging Face token:\")\n",
        "print(\"1. Go to: https://huggingface.co/settings/tokens\")\n",
        "print(\"2. Click 'New token'\")\n",
        "print(\"3. Choose 'Read' access (sufficient for model downloads)\")\n",
        "print(\"4. Copy the token\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîê Enter your Hugging Face token below:\")\n",
        "\n",
        "# Get token from user\n",
        "try:\n",
        "    # Try to get token securely\n",
        "    token = getpass.getpass(\"Enter your HF token (text will be hidden): \")\n",
        "    \n",
        "    if not token.strip():\n",
        "        print(\"‚ùå No token entered!\")\n",
        "    else:\n",
        "        # Login to Hugging Face\n",
        "        try:\n",
        "            login(token=token.strip(), add_to_git_credential=True)\n",
        "            print(\"‚úÖ Successfully logged in to Hugging Face!\")\n",
        "            \n",
        "            # Set environment variable for this session\n",
        "            os.environ['HF_TOKEN'] = token.strip()\n",
        "            os.environ['HUGGINGFACE_HUB_TOKEN'] = token.strip()\n",
        "            \n",
        "            print(\"üîê Token saved for this session\")\n",
        "            \n",
        "            # Test token by checking whoami\n",
        "            try:\n",
        "                from huggingface_hub import whoami\n",
        "                user_info = whoami()\n",
        "                print(f\"üë§ Logged in as: {user_info['name']}\")\n",
        "            except:\n",
        "                print(\"‚ö†Ô∏è  Token set but couldn't verify user info\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Login failed: {e}\")\n",
        "            print(\"üîÑ Please check your token and try again\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error getting token: {e}\")\n",
        "    print(\"\\nüîß Alternative: Set token manually\")\n",
        "    print(\"Copy and run this with your token:\")\n",
        "    print(\"```\")\n",
        "    print(\"from huggingface_hub import login\")\n",
        "    print(\"login(token='YOUR_TOKEN_HERE')\")\n",
        "    print(\"```\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üí° Your token is only stored for this Colab session\")\n",
        "print(\"üîÑ You'll need to re-enter it if you restart the runtime\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ‚ö†Ô∏è Model Availability Fix\n",
        "\n",
        "**Important**: Some models are not yet available. Here are the ACTUAL available models:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö†Ô∏è MODEL AVAILABILITY CHECK\n",
        "\n",
        "print(\"üìã SkyReels V2 - Currently Available Models\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Available models as of current date\n",
        "available_models = {\n",
        "    \"Text-to-Video\": {\n",
        "        \"14B-540P\": \"‚úÖ Skywork/SkyReels-V2-T2V-14B-540P\",\n",
        "        \"14B-720P\": \"‚úÖ Skywork/SkyReels-V2-T2V-14B-720P\",\n",
        "        \"1.3B-540P\": \"‚ùå Coming Soon\",\n",
        "        \"1.3B-720P\": \"‚ùå Not Available\"\n",
        "    },\n",
        "    \"Image-to-Video\": {\n",
        "        \"1.3B-540P\": \"‚úÖ Skywork/SkyReels-V2-I2V-1.3B-540P\",\n",
        "        \"14B-540P\": \"‚úÖ Skywork/SkyReels-V2-I2V-14B-540P\", \n",
        "        \"14B-720P\": \"‚úÖ Skywork/SkyReels-V2-I2V-14B-720P\",\n",
        "        \"1.3B-720P\": \"‚ùå Not Available\"\n",
        "    },\n",
        "    \"Diffusion Forcing\": {\n",
        "        \"1.3B-540P\": \"‚úÖ Skywork/SkyReels-V2-DF-1.3B-540P\",\n",
        "        \"14B-540P\": \"‚úÖ Skywork/SkyReels-V2-DF-14B-540P\",\n",
        "        \"14B-720P\": \"‚úÖ Skywork/SkyReels-V2-DF-14B-720P\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for model_type, models in available_models.items():\n",
        "    print(f\"\\nüé¨ {model_type}:\")\n",
        "    for size, status in models.items():\n",
        "        print(f\"   {size}: {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üí° RECOMMENDATIONS:\")\n",
        "print(\"üì± For limited GPU memory (T4): Use Image-to-Video 1.3B-540P\")\n",
        "print(\"üöÄ For Text-to-Video: Use 14B models (requires more GPU memory)\")\n",
        "print(\"üé• For long videos: Use Diffusion Forcing models\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  CURRENT ISSUE:\")\n",
        "print(\"‚ùå Text-to-Video 1.3B models are not yet available!\")\n",
        "print(\"‚úÖ Use Image-to-Video 1.3B-540P or Text-to-Video 14B instead\")\n",
        "\n",
        "print(\"\\nüîß Quick Fix for your error:\")\n",
        "print(\"Change the interface settings to:\")\n",
        "print(\"- Model Type: Image-to-Video\") \n",
        "print(\"- Model Size: 1.3B\")\n",
        "print(\"- Resolution: 540P\")\n",
        "print(\"OR\")\n",
        "print(\"- Model Type: Text-to-Video\")\n",
        "print(\"- Model Size: 14B\") \n",
        "print(\"- Resolution: 540P\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üé® Updated Gradio Interface (With Correct Models)\n",
        "\n",
        "This version only shows available model combinations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üé® UPDATED INTERFACE WITH CORRECT MODEL VALIDATION\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Available model combinations\n",
        "AVAILABLE_MODELS = {\n",
        "    (\"Text-to-Video\", \"14B\", \"540P\"): \"Skywork/SkyReels-V2-T2V-14B-540P\",\n",
        "    (\"Text-to-Video\", \"14B\", \"720P\"): \"Skywork/SkyReels-V2-T2V-14B-720P\", \n",
        "    (\"Image-to-Video\", \"1.3B\", \"540P\"): \"Skywork/SkyReels-V2-I2V-1.3B-540P\",\n",
        "    (\"Image-to-Video\", \"14B\", \"540P\"): \"Skywork/SkyReels-V2-I2V-14B-540P\",\n",
        "    (\"Image-to-Video\", \"14B\", \"720P\"): \"Skywork/SkyReels-V2-I2V-14B-720P\",\n",
        "}\n",
        "\n",
        "class SmartSkyReelsInterface:\n",
        "    def __init__(self):\n",
        "        self.pipeline = None\n",
        "        self.current_model = None\n",
        "    \n",
        "    def validate_and_generate(self, prompt, image, model_type, model_size, resolution,\n",
        "                            num_frames, guidance_scale, shift, steps, fps, seed, \n",
        "                            use_offload, progress=gr.Progress()):\n",
        "        \n",
        "        # Validate model combination\n",
        "        combo = (model_type, model_size, resolution)\n",
        "        if combo not in AVAILABLE_MODELS:\n",
        "            available_list = \"\\\\n\".join([f\"  - {mt} {ms} {res}\" \n",
        "                                       for mt, ms, res in AVAILABLE_MODELS.keys()])\n",
        "            return None, f\"‚ùå Model combination not available!\\\\n\\\\nAvailable combinations:\\\\n{available_list}\"\n",
        "        \n",
        "        model_id = AVAILABLE_MODELS[combo]\n",
        "        \n",
        "        try:\n",
        "            progress(0, \"Initializing...\")\n",
        "            \n",
        "            # Import required modules (with error handling)\n",
        "            try:\n",
        "                from skyreels_v2_infer.modules import download_model\n",
        "                from skyreels_v2_infer.pipelines import Image2VideoPipeline, Text2VideoPipeline\n",
        "                from skyreels_v2_infer.pipelines import resizecrop\n",
        "            except ImportError as e:\n",
        "                return None, f\"‚ùå Module import failed: {e}\\\\nüîÑ Please run the setup cells above first!\"\n",
        "            \n",
        "            progress(0.1, \"Loading model...\")\n",
        "            model_path = download_model(model_id)\n",
        "            \n",
        "            # Set seed\n",
        "            if seed == -1:\n",
        "                seed = random.randint(0, 2147483647)\n",
        "            \n",
        "            # Set dimensions\n",
        "            height, width = (544, 960) if resolution == \"540P\" else (720, 1280)\n",
        "            \n",
        "            progress(0.3, \"Initializing pipeline...\")\n",
        "            \n",
        "            # Create pipeline if needed\n",
        "            if self.current_model != model_id:\n",
        "                if self.pipeline:\n",
        "                    del self.pipeline\n",
        "                    torch.cuda.empty_cache()\n",
        "                \n",
        "                if model_type == \"Text-to-Video\":\n",
        "                    self.pipeline = Text2VideoPipeline(\n",
        "                        model_path=model_path, \n",
        "                        dit_path=model_path, \n",
        "                        use_usp=False, \n",
        "                        offload=use_offload\n",
        "                    )\n",
        "                else:\n",
        "                    self.pipeline = Image2VideoPipeline(\n",
        "                        model_path=model_path, \n",
        "                        dit_path=model_path, \n",
        "                        use_usp=False, \n",
        "                        offload=use_offload\n",
        "                    )\n",
        "                \n",
        "                self.current_model = model_id\n",
        "            \n",
        "            progress(0.5, \"Generating video...\")\n",
        "            \n",
        "            # Prepare inputs\n",
        "            kwargs = {\n",
        "                \"prompt\": prompt,\n",
        "                \"negative_prompt\": \"worst quality, low quality, static\",\n",
        "                \"num_frames\": num_frames,\n",
        "                \"num_inference_steps\": steps,\n",
        "                \"guidance_scale\": guidance_scale,\n",
        "                \"shift\": shift,\n",
        "                \"generator\": torch.Generator(device=\"cuda\").manual_seed(seed),\n",
        "                \"height\": height,\n",
        "                \"width\": width,\n",
        "            }\n",
        "            \n",
        "            # Add image if provided\n",
        "            if image is not None:\n",
        "                img = Image.fromarray(image).convert(\"RGB\")\n",
        "                if img.height > img.width:\n",
        "                    height, width = width, height\n",
        "                kwargs[\"image\"] = resizecrop(img, height, width)\n",
        "            \n",
        "            # Generate\n",
        "            with torch.cuda.amp.autocast(dtype=self.pipeline.transformer.dtype), torch.no_grad():\n",
        "                frames = self.pipeline(**kwargs)[0]\n",
        "            \n",
        "            progress(0.9, \"Saving...\")\n",
        "            \n",
        "            # Save video\n",
        "            os.makedirs(\"outputs\", exist_ok=True)\n",
        "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"video_{timestamp}_{seed}.mp4\"\n",
        "            path = os.path.join(\"outputs\", filename)\n",
        "            \n",
        "            imageio.mimwrite(path, frames, fps=fps, quality=8)\n",
        "            \n",
        "            # Clear memory\n",
        "            del frames\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            \n",
        "            progress(1.0, \"Done!\")\n",
        "            \n",
        "            info = f\"‚úÖ Generated video\\\\nModel: {model_id}\\\\nSeed: {seed}\\\\nFile: {filename}\"\n",
        "            return path, info\n",
        "            \n",
        "        except Exception as e:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            return None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "\n",
        "# Create interface\n",
        "smart_interface = SmartSkyReelsInterface()\n",
        "\n",
        "def create_smart_interface():\n",
        "    with gr.Blocks(title=\"SkyReels V2 - Smart Interface\", theme=gr.themes.Soft()) as app:\n",
        "        gr.HTML(\"<h1 align='center'>üé¨ SkyReels V2 - Smart Interface</h1>\")\n",
        "        gr.HTML(\"<p align='center'>Only shows available model combinations</p>\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                prompt = gr.Textbox(\n",
        "                    label=\"Prompt\", \n",
        "                    lines=3,\n",
        "                    value=\"A beautiful swan swimming gracefully in a serene lake at dawn\"\n",
        "                )\n",
        "                \n",
        "                image = gr.Image(label=\"Input Image (for I2V)\", type=\"numpy\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    model_type = gr.Dropdown(\n",
        "                        [\"Image-to-Video\", \"Text-to-Video\"],  # I2V first (has 1.3B option)\n",
        "                        value=\"Image-to-Video\",\n",
        "                        label=\"Type\"\n",
        "                    )\n",
        "                    model_size = gr.Dropdown([\"1.3B\", \"14B\"], value=\"1.3B\", label=\"Size\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    resolution = gr.Dropdown([\"540P\", \"720P\"], value=\"540P\", label=\"Resolution\")\n",
        "                    num_frames = gr.Slider(49, 121, 97, label=\"Frames\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    guidance_scale = gr.Slider(1, 10, 5, label=\"Guidance\")  # Default for I2V\n",
        "                    shift = gr.Slider(1, 10, 3, label=\"Shift\")  # Default for I2V\n",
        "                \n",
        "                with gr.Row():\n",
        "                    steps = gr.Slider(10, 100, 50, label=\"Steps\")\n",
        "                    fps = gr.Slider(8, 30, 24, label=\"FPS\")\n",
        "                \n",
        "                seed = gr.Number(label=\"Seed (-1 = random)\", value=-1)\n",
        "                use_offload = gr.Checkbox(label=\"CPU Offload\", value=True)\n",
        "                \n",
        "                btn = gr.Button(\"üé¨ Generate Video\", variant=\"primary\")\n",
        "                \n",
        "                # Model validation info\n",
        "                gr.HTML(\"\"\"\n",
        "                <div style='background: #f0f0f0; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
        "                <strong>Available Models:</strong><br>\n",
        "                ‚Ä¢ Text-to-Video: Only 14B (540P/720P)<br>\n",
        "                ‚Ä¢ Image-to-Video: 1.3B (540P) + 14B (540P/720P)<br>\n",
        "                <em>üí° For limited GPU: Use Image-to-Video 1.3B 540P</em>\n",
        "                </div>\n",
        "                \"\"\")\n",
        "            \n",
        "            with gr.Column():\n",
        "                video_out = gr.Video(label=\"Generated Video\")\n",
        "                info_out = gr.Textbox(label=\"Info\", lines=4)\n",
        "        \n",
        "        # Auto-adjust guidance/shift based on model type\n",
        "        def update_params(model_type_val):\n",
        "            if model_type_val == \"Text-to-Video\":\n",
        "                return gr.update(value=6.0), gr.update(value=8.0)\n",
        "            else:\n",
        "                return gr.update(value=5.0), gr.update(value=3.0)\n",
        "        \n",
        "        model_type.change(\n",
        "            update_params,\n",
        "            inputs=[model_type],\n",
        "            outputs=[guidance_scale, shift]\n",
        "        )\n",
        "        \n",
        "        btn.click(\n",
        "            smart_interface.validate_and_generate,\n",
        "            inputs=[prompt, image, model_type, model_size, resolution, \n",
        "                   num_frames, guidance_scale, shift, steps, fps, seed, use_offload],\n",
        "            outputs=[video_out, info_out]\n",
        "        )\n",
        "    \n",
        "    return app\n",
        "\n",
        "# Launch interface\n",
        "print(\"‚úÖ Smart interface created with model validation\")\n",
        "smart_app = create_smart_interface()\n",
        "smart_app.launch(share=True, debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üí° Quick Solution Summary\n",
        "\n",
        "**Das Problem:** \n",
        "‚ùå Der Text-to-Video 1.3B Modell ist noch nicht verf√ºgbar (404 Error)\n",
        "\n",
        "**Die L√∂sung:** \n",
        "‚úÖ Verwende stattdessen eine verf√ºgbare Kombination:\n",
        "\n",
        "1. **F√ºr begrenzte GPU Memory (T4):**\n",
        "   - Modell-Typ: **Image-to-Video**\n",
        "   - Modell-Gr√∂√üe: **1.3B**\n",
        "   - Aufl√∂sung: **540P**\n",
        "\n",
        "2. **F√ºr Text-to-Video:**\n",
        "   - Modell-Typ: **Text-to-Video**\n",
        "   - Modell-Gr√∂√üe: **14B** (ben√∂tigt mehr GPU Memory)\n",
        "   - Aufl√∂sung: **540P**\n",
        "\n",
        "**N√§chste Schritte:**\n",
        "1. F√ºhre die Modell-Verf√ºgbarkeits-Check-Zelle aus (oben)\n",
        "2. Nutze die aktualisierte Smart Interface (darunter)\n",
        "3. W√§hle eine verf√ºgbare Modell-Kombination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîß GPU Check and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# Check GPU availability and memory\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"üöÄ GPU: {gpu_name}\")\n",
        "    print(f\"üíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
        "    \n",
        "    # Recommend model based on GPU memory\n",
        "    if gpu_memory >= 45:\n",
        "        recommended_model = \"14B models (all resolutions)\"\n",
        "    elif gpu_memory >= 15:\n",
        "        recommended_model = \"1.3B models or 14B-540P with offloading\"\n",
        "    else:\n",
        "        recommended_model = \"1.3B models with heavy offloading\"\n",
        "    \n",
        "    print(f\"üìù Recommended: {recommended_model}\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU available. Please enable GPU in Runtime > Change runtime type\")\n",
        "\n",
        "# Clear cache\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üé® Gradio Interface Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure we're in the right directory and dependencies are installed\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "\n",
        "# Check if we're in SkyReels-V2 directory\n",
        "if not os.path.exists(\"skyreels_v2_infer\"):\n",
        "    print(\"‚ö†Ô∏è  skyreels_v2_infer not found!\")\n",
        "    print(\"üîÑ Please run the Quick Setup cell above first!\")\n",
        "    print(\"üìç Or manually run: %cd /content/SkyReels-V2\")\n",
        "    raise ImportError(\"Please run the Quick Setup cell above to clone the repository and install dependencies\")\n",
        "\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add current directory to Python path\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.append(current_dir)\n",
        "\n",
        "# Import required modules\n",
        "import gradio as gr\n",
        "import time\n",
        "import random\n",
        "import imageio\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from diffusers.utils import load_image\n",
        "import torch\n",
        "\n",
        "# Import SkyReels modules\n",
        "try:\n",
        "    from skyreels_v2_infer.modules import download_model\n",
        "    from skyreels_v2_infer.pipelines import Image2VideoPipeline, Text2VideoPipeline\n",
        "    from skyreels_v2_infer.pipelines import PromptEnhancer, resizecrop\n",
        "    print(\"‚úÖ All SkyReels modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"üîÑ Please run the Quick Setup cell above first!\")\n",
        "    print(\"üì¶ Or install missing dependencies: !pip install decord av dashscope\")\n",
        "    raise\n",
        "\n",
        "class SkyReelsV2Interface:\n",
        "    def __init__(self):\n",
        "        self.current_pipeline = None\n",
        "        self.current_model_id = None\n",
        "        \n",
        "    def generate_video(self, \n",
        "                      prompt, \n",
        "                      image,\n",
        "                      model_type,\n",
        "                      model_size,\n",
        "                      resolution,\n",
        "                      num_frames,\n",
        "                      guidance_scale,\n",
        "                      shift,\n",
        "                      inference_steps,\n",
        "                      fps,\n",
        "                      seed,\n",
        "                      use_prompt_enhancer,\n",
        "                      use_offload,\n",
        "                      progress=gr.Progress()):\n",
        "        \n",
        "        try:\n",
        "            progress(0, desc=\"Initializing...\")\n",
        "            \n",
        "            # Determine model ID\n",
        "            if model_type == \"Text-to-Video\":\n",
        "                if model_size == \"14B\":\n",
        "                    model_id = f\"Skywork/SkyReels-V2-T2V-14B-{resolution}\"\n",
        "                else:\n",
        "                    model_id = f\"Skywork/SkyReels-V2-T2V-1.3B-{resolution}\"\n",
        "            else:  # Image-to-Video\n",
        "                if model_size == \"14B\":\n",
        "                    model_id = f\"Skywork/SkyReels-V2-I2V-14B-{resolution}\"\n",
        "                else:\n",
        "                    model_id = f\"Skywork/SkyReels-V2-I2V-1.3B-{resolution}\"\n",
        "            \n",
        "            progress(0.1, desc=\"Downloading model...\")\n",
        "            model_path = download_model(model_id)\n",
        "            \n",
        "            # Set seed\n",
        "            if seed == -1:\n",
        "                seed = random.randint(0, 2147483647)\n",
        "            \n",
        "            # Set dimensions\n",
        "            if resolution == \"540P\":\n",
        "                height, width = 544, 960\n",
        "            else:  # 720P\n",
        "                height, width = 720, 1280\n",
        "            \n",
        "            progress(0.2, desc=\"Processing prompt...\")\n",
        "            prompt_input = prompt\n",
        "            \n",
        "            # Enhance prompt if requested and no image provided\n",
        "            if use_prompt_enhancer and image is None:\n",
        "                try:\n",
        "                    progress(0.25, desc=\"Enhancing prompt...\")\n",
        "                    enhancer = PromptEnhancer()\n",
        "                    prompt_input = enhancer(prompt)\n",
        "                    del enhancer\n",
        "                    torch.cuda.empty_cache()\n",
        "                    print(f\"Enhanced prompt: {prompt_input}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Prompt enhancement failed: {e}\")\n",
        "                    prompt_input = prompt\n",
        "            \n",
        "            progress(0.3, desc=\"Loading pipeline...\")\n",
        "            \n",
        "            # Initialize pipeline\n",
        "            if image is None:\n",
        "                if self.current_model_id != model_id or self.current_pipeline is None:\n",
        "                    if self.current_pipeline:\n",
        "                        del self.current_pipeline\n",
        "                        torch.cuda.empty_cache()\n",
        "                    \n",
        "                    self.current_pipeline = Text2VideoPipeline(\n",
        "                        model_path=model_path, \n",
        "                        dit_path=model_path, \n",
        "                        use_usp=False, \n",
        "                        offload=use_offload\n",
        "                    )\n",
        "                    self.current_model_id = model_id\n",
        "            else:\n",
        "                if self.current_model_id != model_id or self.current_pipeline is None:\n",
        "                    if self.current_pipeline:\n",
        "                        del self.current_pipeline\n",
        "                        torch.cuda.empty_cache()\n",
        "                    \n",
        "                    self.current_pipeline = Image2VideoPipeline(\n",
        "                        model_path=model_path, \n",
        "                        dit_path=model_path, \n",
        "                        use_usp=False, \n",
        "                        offload=use_offload\n",
        "                    )\n",
        "                    self.current_model_id = model_id\n",
        "                \n",
        "                # Process input image\n",
        "                input_image = Image.fromarray(image).convert(\"RGB\")\n",
        "                image_width, image_height = input_image.size\n",
        "                if image_height > image_width:\n",
        "                    height, width = width, height\n",
        "                input_image = resizecrop(input_image, height, width)\n",
        "            \n",
        "            progress(0.5, desc=\"Generating video...\")\n",
        "            \n",
        "            # Prepare generation parameters\n",
        "            negative_prompt = \"Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards\"\n",
        "            \n",
        "            kwargs = {\n",
        "                \"prompt\": prompt_input,\n",
        "                \"negative_prompt\": negative_prompt,\n",
        "                \"num_frames\": num_frames,\n",
        "                \"num_inference_steps\": inference_steps,\n",
        "                \"guidance_scale\": guidance_scale,\n",
        "                \"shift\": shift,\n",
        "                \"generator\": torch.Generator(device=\"cuda\").manual_seed(seed),\n",
        "                \"height\": height,\n",
        "                \"width\": width,\n",
        "            }\n",
        "            \n",
        "            if image is not None:\n",
        "                kwargs[\"image\"] = input_image\n",
        "            \n",
        "            # Generate video\n",
        "            with torch.cuda.amp.autocast(dtype=self.current_pipeline.transformer.dtype), torch.no_grad():\n",
        "                video_frames = self.current_pipeline(**kwargs)[0]\n",
        "            \n",
        "            progress(0.9, desc=\"Saving video...\")\n",
        "            \n",
        "            # Save video\n",
        "            os.makedirs(\"outputs\", exist_ok=True)\n",
        "            current_time = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
        "            video_filename = f\"skyreels_v2_{current_time}_{seed}.mp4\"\n",
        "            video_path = os.path.join(\"outputs\", video_filename)\n",
        "            \n",
        "            imageio.mimwrite(video_path, video_frames, fps=fps, quality=8, output_params=[\"-loglevel\", \"error\"])\n",
        "            \n",
        "            progress(1.0, desc=\"Complete!\")\n",
        "            \n",
        "            return video_path, f\"‚úÖ Video generated successfully!\\\\nSeed: {seed}\\\\nFrames: {len(video_frames)}\\\\nResolution: {width}x{height}\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = f\"‚ùå Error: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return None, error_msg\n",
        "\n",
        "# Create interface instance\n",
        "skyreels_interface = SkyReelsV2Interface()\n",
        "\n",
        "print(\"‚úÖ Interface setup completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üåü Launch Interactive Interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Gradio interface\n",
        "def create_interface():\n",
        "    with gr.Blocks(title=\"SkyReels V2 - Video Generator\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "            <h1>üé¨ SkyReels V2 - Infinite-Length Film Generator</h1>\n",
        "            <p>Generate high-quality videos with state-of-the-art AI models</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        \n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### üìù Input Configuration\")\n",
        "                \n",
        "                prompt = gr.Textbox(\n",
        "                    label=\"Prompt\",\n",
        "                    placeholder=\"Describe the video you want to generate...\",\n",
        "                    lines=3,\n",
        "                    value=\"A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface.\"\n",
        "                )\n",
        "                \n",
        "                image = gr.Image(\n",
        "                    label=\"Input Image (Optional - for Image-to-Video)\",\n",
        "                    type=\"numpy\"\n",
        "                )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    model_type = gr.Dropdown(\n",
        "                        choices=[\"Text-to-Video\", \"Image-to-Video\"],\n",
        "                        value=\"Text-to-Video\",\n",
        "                        label=\"Generation Type\"\n",
        "                    )\n",
        "                    \n",
        "                    model_size = gr.Dropdown(\n",
        "                        choices=[\"1.3B\", \"14B\"],\n",
        "                        value=\"1.3B\",\n",
        "                        label=\"Model Size\"\n",
        "                    )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    resolution = gr.Dropdown(\n",
        "                        choices=[\"540P\", \"720P\"],\n",
        "                        value=\"540P\",\n",
        "                        label=\"Resolution\"\n",
        "                    )\n",
        "                    \n",
        "                    num_frames = gr.Slider(\n",
        "                        minimum=49,\n",
        "                        maximum=121,\n",
        "                        value=97,\n",
        "                        step=1,\n",
        "                        label=\"Number of Frames\"\n",
        "                    )\n",
        "                \n",
        "                gr.Markdown(\"### ‚öôÔ∏è Advanced Settings\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    guidance_scale = gr.Slider(\n",
        "                        minimum=1.0,\n",
        "                        maximum=10.0,\n",
        "                        value=6.0,\n",
        "                        step=0.5,\n",
        "                        label=\"Guidance Scale\"\n",
        "                    )\n",
        "                    \n",
        "                    shift = gr.Slider(\n",
        "                        minimum=1.0,\n",
        "                        maximum=10.0,\n",
        "                        value=8.0,\n",
        "                        step=0.5,\n",
        "                        label=\"Shift\"\n",
        "                    )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    inference_steps = gr.Slider(\n",
        "                        minimum=10,\n",
        "                        maximum=100,\n",
        "                        value=50,\n",
        "                        step=1,\n",
        "                        label=\"Inference Steps\"\n",
        "                    )\n",
        "                    \n",
        "                    fps = gr.Slider(\n",
        "                        minimum=8,\n",
        "                        maximum=30,\n",
        "                        value=24,\n",
        "                        step=1,\n",
        "                        label=\"FPS\"\n",
        "                    )\n",
        "                \n",
        "                seed = gr.Number(\n",
        "                    label=\"Seed (-1 for random)\",\n",
        "                    value=-1,\n",
        "                    precision=0\n",
        "                )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    use_prompt_enhancer = gr.Checkbox(\n",
        "                        label=\"Enhance Prompt\",\n",
        "                        value=False\n",
        "                    )\n",
        "                    \n",
        "                    use_offload = gr.Checkbox(\n",
        "                        label=\"CPU Offload (reduces VRAM)\",\n",
        "                        value=True\n",
        "                    )\n",
        "                \n",
        "                generate_btn = gr.Button(\n",
        "                    \"üé¨ Generate Video\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "            \n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### üé• Generated Video\")\n",
        "                \n",
        "                output_video = gr.Video(\n",
        "                    label=\"Generated Video\",\n",
        "                    height=400\n",
        "                )\n",
        "                \n",
        "                output_info = gr.Textbox(\n",
        "                    label=\"Generation Info\",\n",
        "                    lines=4,\n",
        "                    interactive=False\n",
        "                )\n",
        "                \n",
        "                gr.Markdown(\"\"\"\n",
        "                ### üí° Tips:\n",
        "                - **1.3B models**: Faster, lower VRAM usage (~15GB)\n",
        "                - **14B models**: Higher quality, more VRAM (~45GB)\n",
        "                - **540P**: 544x960 resolution, 97 frames max\n",
        "                - **720P**: 720x1280 resolution, 121 frames max\n",
        "                - **CPU Offload**: Reduces VRAM usage but slower\n",
        "                - **Image-to-Video**: Upload an image for I2V generation\n",
        "                \"\"\")\n",
        "        \n",
        "        # Auto-adjust parameters based on model type\n",
        "        def update_params(model_type):\n",
        "            if model_type == \"Image-to-Video\":\n",
        "                return gr.update(value=5.0), gr.update(value=3.0)  # guidance_scale, shift\n",
        "            else:\n",
        "                return gr.update(value=6.0), gr.update(value=8.0)\n",
        "        \n",
        "        model_type.change(\n",
        "            update_params,\n",
        "            inputs=[model_type],\n",
        "            outputs=[guidance_scale, shift]\n",
        "        )\n",
        "        \n",
        "        # Auto-adjust frames based on resolution\n",
        "        def update_frames(resolution):\n",
        "            if resolution == \"720P\":\n",
        "                return gr.update(maximum=121, value=121)\n",
        "            else:\n",
        "                return gr.update(maximum=97, value=97)\n",
        "        \n",
        "        resolution.change(\n",
        "            update_frames,\n",
        "            inputs=[resolution],\n",
        "            outputs=[num_frames]\n",
        "        )\n",
        "        \n",
        "        # Generate video\n",
        "        generate_btn.click(\n",
        "            skyreels_interface.generate_video,\n",
        "            inputs=[\n",
        "                prompt, image, model_type, model_size, resolution,\n",
        "                num_frames, guidance_scale, shift, inference_steps,\n",
        "                fps, seed, use_prompt_enhancer, use_offload\n",
        "            ],\n",
        "            outputs=[output_video, output_info]\n",
        "        )\n",
        "    \n",
        "    return demo\n",
        "\n",
        "# Launch the interface\n",
        "demo = create_interface()\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True,\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860,\n",
        "    show_error=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üìö Example Usage\n",
        "\n",
        "Here are some example prompts and settings to get you started:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example prompts for different scenarios\n",
        "example_prompts = {\n",
        "    \"Nature\": \"A majestic waterfall cascading down moss-covered rocks in a lush forest, with sunbeams filtering through the canopy and mist rising from the pool below.\",\n",
        "    \n",
        "    \"Urban\": \"A bustling city street at night with neon lights reflecting on wet pavement, people walking with umbrellas, and cars passing by with light trails.\",\n",
        "    \n",
        "    \"Portrait\": \"A close-up portrait of a person with curly hair sitting by a window, soft natural light illuminating their face, gentle smile, looking thoughtfully outside.\",\n",
        "    \n",
        "    \"Abstract\": \"Colorful paint drops falling into water in slow motion, creating beautiful ripples and color mixing patterns, artistic and mesmerizing.\",\n",
        "    \n",
        "    \"Animals\": \"A family of dolphins jumping gracefully out of crystal clear ocean water at sunset, with golden light reflecting on the waves.\"\n",
        "}\n",
        "\n",
        "print(\"üìö Example Prompts:\")\n",
        "for category, prompt in example_prompts.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    print(f\"  {prompt}\")\n",
        "\n",
        "print(\"\\nüí° Pro Tips:\")\n",
        "print(\"- Use descriptive language with visual details\")\n",
        "print(\"- Specify lighting, camera angles, and movement\")\n",
        "print(\"- Mention colors, textures, and atmosphere\")\n",
        "print(\"- Keep prompts between 20-100 words for best results\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## üîß Troubleshooting\n",
        "\n",
        "Common issues and solutions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_system_status():\n",
        "    \"\"\"Check system status and provide troubleshooting info\"\"\"\n",
        "    \n",
        "    print(\"=== System Status Check ===\")\n",
        "    \n",
        "    # GPU Check\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
        "        gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        gpu_memory_free = gpu_memory_total - gpu_memory_allocated\n",
        "        \n",
        "        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"üíæ GPU Memory: {gpu_memory_allocated:.2f}GB / {gpu_memory_total:.2f}GB used\")\n",
        "        print(f\"üÜì Free Memory: {gpu_memory_free:.2f}GB\")\n",
        "        \n",
        "        if gpu_memory_free < 10:\n",
        "            print(\"‚ö†Ô∏è  Warning: Low GPU memory. Consider:\")\n",
        "            print(\"   - Using 1.3B model instead of 14B\")\n",
        "            print(\"   - Enabling CPU offload\")\n",
        "            print(\"   - Reducing number of frames\")\n",
        "            print(\"   - Using 540P instead of 720P\")\n",
        "    else:\n",
        "        print(\"‚ùå No GPU detected. Please enable GPU runtime.\")\n",
        "    \n",
        "    # Memory cleanup\n",
        "    print(\"\\nüßπ Cleaning up memory...\")\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"‚úÖ Memory cleanup completed\")\n",
        "    \n",
        "    # Disk space\n",
        "    import shutil\n",
        "    disk_usage = shutil.disk_usage('.')\n",
        "    free_gb = disk_usage.free / 1024**3\n",
        "    print(f\"üíΩ Free Disk Space: {free_gb:.2f}GB\")\n",
        "    \n",
        "    if free_gb < 5:\n",
        "        print(\"‚ö†Ô∏è  Warning: Low disk space. Clean up old files if needed.\")\n",
        "\n",
        "# Run system check\n",
        "check_system_status()\n",
        "\n",
        "print(\"\\nüÜò Common Issues & Solutions:\")\n",
        "print(\"\\n1. Out of Memory Error:\")\n",
        "print(\"   - Use smaller model (1.3B instead of 14B)\")\n",
        "print(\"   - Enable CPU offload\")\n",
        "print(\"   - Reduce number of frames\")\n",
        "print(\"   - Use 540P resolution\")\n",
        "\n",
        "print(\"\\n2. Generation Takes Too Long:\")\n",
        "print(\"   - Reduce inference steps (20-30)\")\n",
        "print(\"   - Use smaller model\")\n",
        "print(\"   - Disable prompt enhancer\")\n",
        "\n",
        "print(\"\\n3. Poor Video Quality:\")\n",
        "print(\"   - Use larger model (14B)\")\n",
        "print(\"   - Increase inference steps (50-100)\")\n",
        "print(\"   - Improve prompt description\")\n",
        "print(\"   - Adjust guidance scale (5-8)\")\n",
        "\n",
        "print(\"\\n4. Installation Issues:\")\n",
        "print(\"   - Restart runtime and run cells again\")\n",
        "print(\"   - Check GPU is enabled in runtime settings\")\n",
        "print(\"   - Clear output and restart if needed\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
